---
layout: post
title:  "Pre-GSoC"
date: 2021-04-19 13:49:09 +0530
categories: jekyll update
---


Hi All,

Quite a few days since I've posted a blog post. Summarizing the few incidents that happened during this period were:

- I finalized and made changes to my draft proposal (We discussed on the DOM characteristics of websites and how effective would it be)
- I wrote a [Fetcher](https://github.com/Hackhard/Fetcher/blob/main/exp.py) that checks for the number of DOM nodes and the length of Total HTML, to get to a perspective.

That said, there are quite a few things I observed and this post would be on it.


Certain websites like [Google](https://www.google.com) and [YouTube](https://www.youtube.com) on opening through Selenium browser [displays a popup(iframe)](https://stackoverflow.com/questions/64846902/how-to-get-rid-of-the-google-cookie-pop-up-with-my-selenium-automation).
This makes it difficult to compare[1]. For some websites like [Lloyds Bank](https://www.lloydsbank.com/) and [Dan.me.uk](https://dan.me.uk) it works (that shows error page), but for some dynamic websites that change content according to the region/ip like [Bing](https://www.bing.com/) it doesn't give a satisfied data.

**1. Cookie iframe/Popup:**
![tor_ google com](https://user-images.githubusercontent.com/34208125/115275027-e3749c00-a15e-11eb-8385-32fca0b18aec.png)

This kind of cookie hinders results, therefore one possible way is to programmatically remove these iframes by letting Selenium click on the Allow box (not displayed in the screenshot).
The other way that I think of dealing this would be using a cookie from the Non-Tor Selenium browsing, because if using Selenium or Automation results into this cookie popup thing, I think Non-Tor exit nodes should have generated a similar screenshot. But No!

**1. Difference between total DOM nodes:**

What if the difference in the total nodes are large but still the website doesn't generate any errors? Like [Bing](https://www.bing.com) for example, during a trial resulted into the following data:
 
  + Length of Total HTML (Non-Tor)     68332
  + Number of DOM nodes (Non-Tor)      227

  ----------------------------------------------
  
  
  + Length of Total HTML (Tor)     63699
  + Number of DOM nodes (Tor)      187


The Screenshots generated were:

Non-Tor Screenshot:

![non-tor_ Bing com](https://user-images.githubusercontent.com/34208125/115283643-466b3080-a169-11eb-8761-7474dd8f86f1.png)

Tor Screenshot:

![tor_ Bing com](https://user-images.githubusercontent.com/34208125/115283651-4834f400-a169-11eb-9678-f406c413b619.png)

Here, a noticeable difference that can be seen in the screenshots are the **Languages:** bar and the cookie permission also. So, in this type of case, problems may arise

[Update: On running the code for bing 2-3 times I saw some noticeable differences, 229 nodes for non-tor browser and 233 nodes for tbb]

That suggests testing a website multiple times and to get an average result and then to determine for the values.
Another thing that could be added up on the before case could be searching for keywords in the generated HTML, for both Tbb and Non-Tor browser. Might be helpful in some cases that could be misleading.

That said, we see that in our Bing case, where the Tbb generated nodes were less, we need to determine what should be our calculated value that we could omit. Mathematically speaking:

            X (VALUE TO BE OMITTED) =  abs| DOM_nodes_Tbb(website) - DOM_nodes_Non_Tbb(website) |
                                          
Because it isn't always a case like Wikipedia or LinkedIn where the number of nodes are the same as there are also cases like Google which presents a cookie popup(if one wants to browse with their cookies saved) etc.
So finding a suitable value for X should help to minimise errors and also to detect if the sites return errors.


Any suggestions would be welcomed!

Thanks for reading  :)
 



